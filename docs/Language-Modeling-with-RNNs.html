{% load static %}
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Deep Learning: RNNs</title>





{#    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>#}
{#    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>#}
    <!-- Loading mathjax macro -->
    <!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
<!-- Custom stylesheet, it must be in the same directory as the html file -->
    {% include 'layout/components/css-head.html' %}
    <link rel="stylesheet" href="{% static 'projects/css/ipynb.custom.css' %}">
    <style>
        a.dropdown-item {
            color: #FAACA8;
            font-size:1.5rem;
        }
        #notebook-container > p {
            font-family: monospace, monospace;
        }
    </style>
</head>
<body>
{% include 'layout/components/navbar.html' %}

  <div tabindex="-1" id="notebook" class="border-box-sizing bg-gradient">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Language-Modeling-with-RNNs">Language Modeling with RNNs<a class="anchor-link" href="#Language-Modeling-with-RNNs">&#182;</a></h1><ul>
<li><b>Objective:</b> Understand Recurrent Neural Networks by implementing a vanilla RNN and an LSTM to train a model that can generate text</li>
<li>See <code>lib/layer_utils.py</code> for the definitions different layer type classes (RNN and LSTM)</li>
<li>See <code>lib/rnn.py</code> for the implementation of the text generation model.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">lib.rnn</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">lib.layer_utils</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">lib.grad_check</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">lib.optim</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">lib.train</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">)</span> <span class="c1"># set default size of plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;image.interpolation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;nearest&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;image.cmap&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span>

<span class="c1"># for auto-reloading external modules</span>
<span class="c1"># see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Vanilla-RNN">Vanilla RNN<a class="anchor-link" href="#Vanilla-RNN">&#182;</a></h1><h2 id="Vanilla-RNN:-step-forward">Vanilla RNN: step forward<a class="anchor-link" href="#Vanilla-RNN:-step-forward">&#182;</a></h2><p>Testing the forward pass for a single timestep 
of a basic RNN cell defined in <code>lib/layer_utils.py</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">4</span>

<span class="n">rnn</span> <span class="o">=</span> <span class="n">VanillaRNN</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rnn_test&quot;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">prev_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>

<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">D</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">H</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">H</span><span class="p">)</span>

<span class="n">next_h</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">)</span>
<span class="n">expected_next_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
  <span class="p">[</span><span class="o">-</span><span class="mf">0.58172089</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.50182032</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.41232771</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.31410098</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.66854692</span><span class="p">,</span>  <span class="mf">0.79562378</span><span class="p">,</span>  <span class="mf">0.87755553</span><span class="p">,</span>  <span class="mf">0.92795967</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.97934501</span><span class="p">,</span>  <span class="mf">0.99144213</span><span class="p">,</span>  <span class="mf">0.99646691</span><span class="p">,</span>  <span class="mf">0.99854353</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">next_h</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;next_h error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">expected_next_h</span><span class="p">,</span> <span class="n">next_h</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>self.params[self.wx_name]  (10, 4)
self.params[self.wh_name]:  (4, 4)
self.params[self.b_name]:  (4,)
[[-0.58172089 -0.50182032 -0.41232771 -0.31410098]
 [ 0.66854692  0.79562378  0.87755553  0.92795967]
 [ 0.97934501  0.99144213  0.99646691  0.99854353]]
next_h error:  6.292421426471037e-09
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Vanilla-RNN:-step-backward">Vanilla RNN: step backward<a class="anchor-link" href="#Vanilla-RNN:-step-backward">&#182;</a></h2><p>Checking the gradient calculations of the <code>VanillaRNN</code> class in the file <code>lib/layer_utils.py</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>
<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span>

<span class="n">rnn</span> <span class="o">=</span> <span class="n">VanillaRNN</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rnn_test&quot;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>

<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wx</span>
<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wh</span>
<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

<span class="n">out</span><span class="p">,</span> <span class="n">meta</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>

<span class="n">dnext_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">dx_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span>
<span class="n">dprev_h_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">h</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">h</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span>
<span class="n">dWx_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">Wx</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Wx</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span>
<span class="n">dWh_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">Wh</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Wh</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span>
<span class="n">db_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">b</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span>

<span class="n">dx</span><span class="p">,</span> <span class="n">dprev_h</span><span class="p">,</span> <span class="n">dWx</span><span class="p">,</span> <span class="n">dWh</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">step_backward</span><span class="p">(</span><span class="n">dnext_h</span><span class="p">,</span> <span class="n">meta</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dx_num</span><span class="p">,</span> <span class="n">dx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dprev_h error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dprev_h_num</span><span class="p">,</span> <span class="n">dprev_h</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dWx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dWx_num</span><span class="p">,</span> <span class="n">dWx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dWh error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dWh_num</span><span class="p">,</span> <span class="n">dWh</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;db error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">db_num</span><span class="p">,</span> <span class="n">db</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>self.params[self.wx_name]  (5, 6)
self.params[self.wh_name]:  (6, 6)
self.params[self.b_name]:  (6,)
dx error:  9.956054783068812e-10
dprev_h error:  2.349821195946612e-10
dWx error:  1.9370107669274995e-10
dWh error:  3.186343591539138e-10
db error:  6.415453358481749e-11
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Vanilla-RNN:-forward">Vanilla RNN: forward<a class="anchor-link" href="#Vanilla-RNN:-forward">&#182;</a></h2><p>Test <code>VanillaRNN</code> by processing a sequence of data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span>

<span class="n">rnn</span> <span class="o">=</span> <span class="n">VanillaRNN</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rnn_test&quot;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">T</span><span class="o">*</span><span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">D</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">H</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">H</span><span class="p">)</span>

<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wx</span>
<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wh</span>
<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
<span class="n">expected_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
  <span class="p">[</span>
    <span class="p">[</span><span class="o">-</span><span class="mf">0.42070749</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.27279261</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.11074945</span><span class="p">,</span>  <span class="mf">0.05740409</span><span class="p">,</span>  <span class="mf">0.22236251</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mf">0.39525808</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.22554661</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0409454</span><span class="p">,</span>   <span class="mf">0.14649412</span><span class="p">,</span>  <span class="mf">0.32397316</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mf">0.42305111</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.24223728</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.04287027</span><span class="p">,</span>  <span class="mf">0.15997045</span><span class="p">,</span>  <span class="mf">0.35014525</span><span class="p">],</span>
  <span class="p">],</span>
  <span class="p">[</span>
    <span class="p">[</span><span class="o">-</span><span class="mf">0.55857474</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.39065825</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.19198182</span><span class="p">,</span>  <span class="mf">0.02378408</span><span class="p">,</span>  <span class="mf">0.23735671</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mf">0.27150199</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07088804</span><span class="p">,</span>  <span class="mf">0.13562939</span><span class="p">,</span>  <span class="mf">0.33099728</span><span class="p">,</span>  <span class="mf">0.50158768</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mf">0.51014825</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.30524429</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.06755202</span><span class="p">,</span>  <span class="mf">0.17806392</span><span class="p">,</span>  <span class="mf">0.40333043</span><span class="p">]]])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;expected_h: &quot;</span><span class="p">,</span><span class="n">expected_h</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;h error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">expected_h</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>self.params[self.wx_name]  (4, 5)
self.params[self.wh_name]:  (5, 5)
self.params[self.b_name]:  (5,)
expected_h:  (2, 3, 5)
h error:  7.728466180186066e-08
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Vanilla-RNN:-backward">Vanilla RNN: backward<a class="anchor-link" href="#Vanilla-RNN:-backward">&#182;</a></h2><p>Test back-propagation over the entire sequence by calling the <code>step_backward</code> function</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span>

<span class="n">rnn</span> <span class="o">=</span> <span class="n">VanillaRNN</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;rnn_test&quot;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>

<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wx</span>
<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wh</span>
<span class="n">rnn</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

<span class="n">dout</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">dx</span><span class="p">,</span> <span class="n">dh0</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>

<span class="n">dx_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">dh0_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">h0</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">h0</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">dWx_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">Wx</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">Wx</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">dWh_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">Wh</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">Wh</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">db_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="n">rnn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">b</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>

<span class="n">dWx</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span>
<span class="n">dWh</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">rnn</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dx_num</span><span class="p">,</span> <span class="n">dx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dh0 error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dh0_num</span><span class="p">,</span> <span class="n">dh0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dWx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dWx_num</span><span class="p">,</span> <span class="n">dWx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dWh error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dWh_num</span><span class="p">,</span> <span class="n">dWh</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;db error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">db_num</span><span class="p">,</span> <span class="n">db</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dh0_num</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dh0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>self.params[self.wx_name]  (3, 5)
self.params[self.wh_name]:  (5, 5)
self.params[self.b_name]:  (5,)
dx error:  2.736928435887175e-08
dh0 error:  8.231409890331713e-10
dWx error:  2.0789178600982087e-08
dWh error:  1.5210912998171804e-08
db error:  2.77914406963907e-10
[[-4.28153694 -2.74230889  0.71964976 -1.18508456 -0.8895025 ]
 [ 0.5942948  -0.86422636 -1.14307499 -0.07620721 -1.10608234]]
[[-4.28153694 -2.74230889  0.71964976 -1.18508456 -0.8895025 ]
 [ 0.5942948  -0.86422636 -1.14307499 -0.07620721 -1.10608234]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Word-embedding">Word embedding<a class="anchor-link" href="#Word-embedding">&#182;</a></h1><h2 id="Word-embedding:-forward">Word embedding: forward<a class="anchor-link" href="#Word-embedding:-forward">&#182;</a></h2><p>Checking implementation of the function <code>forward</code> in the <code>word_embedding</code> class</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span>

<span class="n">we</span> <span class="o">=</span> <span class="n">word_embedding</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;we&quot;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">V</span><span class="o">*</span><span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>

<span class="n">we</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">we</span><span class="o">.</span><span class="n">w_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">W</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">we</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">expected_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
 <span class="p">[[</span> <span class="mf">0.</span><span class="p">,</span>          <span class="mf">0.07142857</span><span class="p">,</span>  <span class="mf">0.14285714</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.64285714</span><span class="p">,</span>  <span class="mf">0.71428571</span><span class="p">,</span>  <span class="mf">0.78571429</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.21428571</span><span class="p">,</span>  <span class="mf">0.28571429</span><span class="p">,</span>  <span class="mf">0.35714286</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.42857143</span><span class="p">,</span>  <span class="mf">0.5</span><span class="p">,</span>         <span class="mf">0.57142857</span><span class="p">]],</span>
 <span class="p">[[</span> <span class="mf">0.42857143</span><span class="p">,</span>  <span class="mf">0.5</span><span class="p">,</span>         <span class="mf">0.57142857</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.21428571</span><span class="p">,</span>  <span class="mf">0.28571429</span><span class="p">,</span>  <span class="mf">0.35714286</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>          <span class="mf">0.07142857</span><span class="p">,</span>  <span class="mf">0.14285714</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.64285714</span><span class="p">,</span>  <span class="mf">0.71428571</span><span class="p">,</span>  <span class="mf">0.78571429</span><span class="p">]]])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;out error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">expected_out</span><span class="p">,</span> <span class="n">out</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[[[0.         0.07142857 0.14285714]
  [0.64285714 0.71428571 0.78571429]
  [0.21428571 0.28571429 0.35714286]
  [0.42857143 0.5        0.57142857]]

 [[0.42857143 0.5        0.57142857]
  [0.21428571 0.28571429 0.35714286]
  [0.         0.07142857 0.14285714]
  [0.64285714 0.71428571 0.78571429]]]
out error:  1.0000000094736443e-08
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Word-embedding:-backward">Word embedding: backward<a class="anchor-link" href="#Word-embedding:-backward">&#182;</a></h2><p>Checking implementation of the function <code>backward</code> in the <code>word_embedding</code> class</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span>

<span class="n">we</span> <span class="o">=</span> <span class="n">word_embedding</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;we&quot;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">))</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>

<span class="n">we</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">we</span><span class="o">.</span><span class="n">w_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">W</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">we</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">dout</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">we</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>

<span class="n">dW</span> <span class="o">=</span> <span class="n">we</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">we</span><span class="o">.</span><span class="n">w_name</span><span class="p">]</span>

<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="n">we</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">dW_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dW error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dW</span><span class="p">,</span> <span class="n">dW_num</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>dW error:  3.2759440934795915e-12
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Temporal-Fully-Connected-layer">Temporal Fully Connected layer<a class="anchor-link" href="#Temporal-Fully-Connected-layer">&#182;</a></h1><p>Checking implementation of the <code>temporal_fc</code> class, which defines a layer that uses an affine function to transform the RNN hidden vector at that timestep into scores for each word in the vocabulary</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>

<span class="c1"># Gradient check for temporal affine layer</span>
<span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span>

<span class="n">t_fc</span> <span class="o">=</span> <span class="n">temporal_fc</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_t_fc&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>

<span class="n">t_fc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">t_fc</span><span class="o">.</span><span class="n">w_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">w</span>
<span class="n">t_fc</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">t_fc</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">t_fc</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">dout</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">dx_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">t_fc</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">dw_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">w</span><span class="p">:</span> <span class="n">t_fc</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">w</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">db_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="n">t_fc</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">b</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>

<span class="n">dx</span> <span class="o">=</span> <span class="n">t_fc</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>
<span class="n">dw</span> <span class="o">=</span> <span class="n">t_fc</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">t_fc</span><span class="o">.</span><span class="n">w_name</span><span class="p">]</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">t_fc</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">t_fc</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dx_num</span><span class="p">,</span> <span class="n">dx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dw error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dw_num</span><span class="p">,</span> <span class="n">dw</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;db error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">db_num</span><span class="p">,</span> <span class="n">db</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>dx error:  3.2269470390098687e-10
dw error:  3.8595619942595054e-11
db error:  1.1455396263586309e-11
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Temporal-Softmax-Cross-Entropy-loss">Temporal Softmax Cross-Entropy loss<a class="anchor-link" href="#Temporal-Softmax-Cross-Entropy-loss">&#182;</a></h1><p>When rolling out a RNN language model to generate a sentence, a score for each word in the vocabulary is produced at every timestep. This score is propotional to the predicted likelihood of this word appearing at the particular timestep in the sentence. Because the ground-truth word at each timestep is known, softmax cross-entropy loss function is used to:</p>
<ul>
<li>Compute a proper probability distribution over the words in the vocabulary at every time step</li>
<li>Compute loss and gradient at each timestep. We sum the losses over time and average them over the minibatch.</li>
</ul>
<p>(Loss function: <code>temporal_softmax_CE_loss</code> in<code>lib/layer_utils.py</code>)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">loss_func</span> <span class="o">=</span> <span class="n">temporal_softmax_CE_loss</span><span class="p">()</span>

<span class="c1"># Sanity check for temporal softmax loss</span>
<span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span>

<span class="k">def</span> <span class="nf">check_loss</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">))</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">p</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
  
<span class="n">check_loss</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>   <span class="c1"># Should be about 2.3</span>
<span class="n">check_loss</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># Should be about 23</span>
<span class="n">check_loss</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span> <span class="c1"># Should be about 2.3</span>

<span class="c1"># Gradient check for temporal softmax loss</span>
<span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">V</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">))</span>
<span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="n">dx</span> <span class="o">=</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="n">dx_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">dx_num</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>2.3026547279318357
23.026307039328714
2.2989009292538665
dx error:  4.0464746298031226e-08
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="RNN-for-language-modeling">RNN for language modeling<a class="anchor-link" href="#RNN-for-language-modeling">&#182;</a></h1><p>Check the forward and backward pass of the <code>TestRNN</code> class using a small test case</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span>
<span class="n">V</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">13</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TestRNN</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">cell_type</span><span class="o">=</span><span class="s1">&#39;rnn&#39;</span><span class="p">)</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">temporal_softmax_CE_loss</span><span class="p">()</span>

<span class="c1"># Set all model parameters to fixed values</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">assign_params</span><span class="p">()</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">D</span> <span class="o">*</span> <span class="n">T</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">H</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span> <span class="o">%</span> <span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

<span class="c1"># You&#39;ll need this</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">))</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="n">dLoss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="n">expected_loss</span> <span class="o">=</span> <span class="mf">51.0949189134</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loss: &#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;expected loss: &#39;</span><span class="p">,</span> <span class="n">expected_loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;difference: &#39;</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">loss</span> <span class="o">-</span> <span class="n">expected_loss</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>self.params[self.wx_name]  (20, 40)
self.params[self.wh_name]:  (40, 40)
self.params[self.b_name]:  (40,)
loss:  51.094918913361184
expected loss:  51.0949189134
difference:  3.881694965457427e-11
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Detailed gradient checking on the backward pass of the <code>TestRNN</code> class</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">timesteps</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">label_size</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">label_size</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">))</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TestRNN</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">cell_type</span><span class="o">=</span><span class="s1">&#39;rnn&#39;</span><span class="p">)</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">temporal_softmax_CE_loss</span><span class="p">()</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

<span class="c1"># You&#39;ll need this</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">))</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="n">dLoss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="n">dout</span><span class="p">,</span> <span class="n">dh0</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dLoss</span><span class="p">)</span>

<span class="n">grads</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">grads</span>

<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">grads</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
    <span class="n">param_grad_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">param_name</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">param_grad_num</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="n">param_name</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> relative error: </span><span class="si">%e</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>self.params[self.wx_name]  (4, 6)
self.params[self.wh_name]:  (6, 6)
self.params[self.b_name]:  (6,)
vanilla_rnn_b relative error: 9.451394e-08
vanilla_rnn_wh relative error: 3.221744e-08
vanilla_rnn_wx relative error: 9.508480e-08
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="LSTM:-Theory">LSTM: Theory<a class="anchor-link" href="#LSTM:-Theory">&#182;</a></h1><p>Vanilla RNNs can be tough to train on long sequences due to vanishing and exploding gradiants. LSTMs solve this problem by replacing the simple update rule in the forward step of the vanilla RNN with a gating mechanism as follows.</p>
<p>Similar to the vanilla RNN, at each timestep we receive an input $x_t\in\mathbb{R}^D$ and the previous hidden state $h_{t-1}\in\mathbb{R}^H$. Crucially, the LSTM also maintains an $H$-dimensional <em>cell state</em>, so we also receive the previous cell state $c_{t-1}\in\mathbb{R}^H$. The learnable parameters of the LSTM are an <em>input-to-hidden</em> matrix $W_x\in\mathbb{R}^{4H\times D}$, a <em>hidden-to-hidden</em> matrix $W_h\in\mathbb{R}^{4H\times H}$ and a <em>bias vector</em> $b\in\mathbb{R}^{4H}$.</p>
<p>At each timestep we first compute an <em>activation vector</em> $a\in\mathbb{R}^{4H}$ as $a=W_xx_t + W_hh_{t-1}+b$. We then divide this into four vectors $a_i,a_f,a_o,a_g\in\mathbb{R}^H$ where $a_i$ consists of the first $H$ elements of $a$, $a_f$ is the next $H$ elements of $a$, etc. We then compute the <em>input gate</em> $g\in\mathbb{R}^H$, <em>forget gate</em> $f\in\mathbb{R}^H$, <em>output gate</em> $o\in\mathbb{R}^H$ and <em>gate gate</em> $g\in\mathbb{R}^H$ as</p>
$$
\begin{align*}
i = \sigma(a_i) \hspace{2pc}
f = \sigma(a_f) \hspace{2pc}
o = \sigma(a_o) \hspace{2pc}
g = \tanh(a_g)
\end{align*}
$$<p>where $\sigma$ is the sigmoid function and $\tanh$ is the hyperbolic tangent, both applied elementwise.</p>
<p>Finally we compute the next cell state $c_t$ and next hidden state $h_t$ as</p>
$$
c_{t} = f\odot c_{t-1} + i\odot g \hspace{4pc}
h_t = o\odot\tanh(c_t)
$$<p>where $\odot$ is the elementwise product of vectors.</p>
<p>In the rest of the notebook we will implement the LSTM update rule and apply it to the text generation task.</p>
<p>In the code, we assume that data is stored in batches so that $X_t \in \mathbb{R}^{N\times D}$, and will work with <em>transposed</em> versions of the parameters: $W_x \in \mathbb{R}^{D \times 4H}$, $W_h \in \mathbb{R}^{H\times 4H}$ so that activations $A \in \mathbb{R}^{N\times 4H}$ can be computed efficiently as $A = X_t W_x + H_{t-1} W_h$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="LSTM:-step-forward">LSTM: step forward<a class="anchor-link" href="#LSTM:-step-forward">&#182;</a></h2><p>Testing <code>lstm.step_forward</code> for a single timestep</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span>

<span class="n">lstm</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_lstm&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">prev_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">prev_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">2.1</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">4</span><span class="o">*</span><span class="n">D</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">4</span><span class="o">*</span><span class="n">H</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">4</span><span class="o">*</span><span class="n">H</span><span class="p">)</span>

<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wx</span>
<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wh</span>
<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

<span class="n">next_h</span><span class="p">,</span> <span class="n">next_c</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)</span>

<span class="n">expected_next_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
    <span class="p">[</span> <span class="mf">0.24635157</span><span class="p">,</span>  <span class="mf">0.28610883</span><span class="p">,</span>  <span class="mf">0.32240467</span><span class="p">,</span>  <span class="mf">0.35525807</span><span class="p">,</span>  <span class="mf">0.38474904</span><span class="p">],</span>
    <span class="p">[</span> <span class="mf">0.49223563</span><span class="p">,</span>  <span class="mf">0.55611431</span><span class="p">,</span>  <span class="mf">0.61507696</span><span class="p">,</span>  <span class="mf">0.66844003</span><span class="p">,</span>  <span class="mf">0.7159181</span> <span class="p">],</span>
    <span class="p">[</span> <span class="mf">0.56735664</span><span class="p">,</span>  <span class="mf">0.66310127</span><span class="p">,</span>  <span class="mf">0.74419266</span><span class="p">,</span>  <span class="mf">0.80889665</span><span class="p">,</span>  <span class="mf">0.858299</span>  <span class="p">]])</span>
<span class="n">expected_next_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
    <span class="p">[</span> <span class="mf">0.32986176</span><span class="p">,</span>  <span class="mf">0.39145139</span><span class="p">,</span>  <span class="mf">0.451556</span><span class="p">,</span>    <span class="mf">0.51014116</span><span class="p">,</span>  <span class="mf">0.56717407</span><span class="p">],</span>
    <span class="p">[</span> <span class="mf">0.66382255</span><span class="p">,</span>  <span class="mf">0.76674007</span><span class="p">,</span>  <span class="mf">0.87195994</span><span class="p">,</span>  <span class="mf">0.97902709</span><span class="p">,</span>  <span class="mf">1.08751345</span><span class="p">],</span>
    <span class="p">[</span> <span class="mf">0.74192008</span><span class="p">,</span>  <span class="mf">0.90592151</span><span class="p">,</span>  <span class="mf">1.07717006</span><span class="p">,</span>  <span class="mf">1.25120233</span><span class="p">,</span>  <span class="mf">1.42395676</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;next_h error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">expected_next_h</span><span class="p">,</span> <span class="n">next_h</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;next_c error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">expected_next_c</span><span class="p">,</span> <span class="n">next_c</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>next_h error:  5.7054131185818695e-09
next_c error:  5.8143123088804145e-09
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="LSTM:-step-backward">LSTM: step backward<a class="anchor-link" href="#LSTM:-step-backward">&#182;</a></h2><p>Testing <code>lstm.step_backward</code> for a single timestep</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span>

<span class="n">lstm</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_lstm&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">prev_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">prev_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>

<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wx</span>
<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wh</span>
<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

<span class="n">next_h</span><span class="p">,</span> <span class="n">next_c</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)</span>

<span class="n">dnext_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">next_h</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">dnext_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">next_c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">fx_h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fh_h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">h</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fc_h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fWx_h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Wx</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fWh_h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Wh</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fb_h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">fx_c</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fh_c</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">h</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fc_c</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fWx_c</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Wx</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fWh_c</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Wh</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fb_c</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">num_grad</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span>

<span class="n">dx_num</span> <span class="o">=</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fx_h</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fx_c</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">dnext_c</span><span class="p">)</span>
<span class="n">dh_num</span> <span class="o">=</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fh_h</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fh_c</span><span class="p">,</span> <span class="n">prev_h</span><span class="p">,</span> <span class="n">dnext_c</span><span class="p">)</span>
<span class="n">dc_num</span> <span class="o">=</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fc_h</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fc_c</span><span class="p">,</span> <span class="n">prev_c</span><span class="p">,</span> <span class="n">dnext_c</span><span class="p">)</span>
<span class="n">dWx_num</span> <span class="o">=</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fWx_h</span><span class="p">,</span> <span class="n">Wx</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fWx_c</span><span class="p">,</span> <span class="n">Wx</span><span class="p">,</span> <span class="n">dnext_c</span><span class="p">)</span>
<span class="n">dWh_num</span> <span class="o">=</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fWh_h</span><span class="p">,</span> <span class="n">Wh</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fWh_c</span><span class="p">,</span> <span class="n">Wh</span><span class="p">,</span> <span class="n">dnext_c</span><span class="p">)</span>
<span class="n">db_num</span> <span class="o">=</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fb_h</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dnext_h</span><span class="p">)</span> <span class="o">+</span> <span class="n">num_grad</span><span class="p">(</span><span class="n">fb_c</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dnext_c</span><span class="p">)</span>

<span class="n">dx</span><span class="p">,</span> <span class="n">dh</span><span class="p">,</span> <span class="n">dc</span><span class="p">,</span> <span class="n">dWx</span><span class="p">,</span> <span class="n">dWh</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">step_backward</span><span class="p">(</span><span class="n">dnext_h</span><span class="p">,</span> <span class="n">dnext_c</span><span class="p">,</span> <span class="n">cache</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dx_num</span><span class="p">,</span> <span class="n">dx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dh error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dh_num</span><span class="p">,</span> <span class="n">dh</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dc error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dc_num</span><span class="p">,</span> <span class="n">dc</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dWx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dWx_num</span><span class="p">,</span> <span class="n">dWx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dWh error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dWh_num</span><span class="p">,</span> <span class="n">dWh</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;db error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">db_num</span><span class="p">,</span> <span class="n">db</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>dx error:  7.10174722192564e-10
dh error:  1.02587271120523e-08
dc error:  1.0127281079074958e-08
dWx error:  7.155327183583897e-08
dWh error:  9.784434021608716e-08
db error:  1.867169717722288e-08
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="LSTM:-forward">LSTM: forward<a class="anchor-link" href="#LSTM:-forward">&#182;</a></h2><p>Testing <code>lstm.forward</code> for an entire timeseries of data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span>

<span class="n">lstm</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_lstm&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">T</span><span class="o">*</span><span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">4</span><span class="o">*</span><span class="n">D</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">4</span><span class="o">*</span><span class="n">H</span><span class="o">*</span><span class="n">H</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">4</span><span class="o">*</span><span class="n">H</span><span class="p">)</span>

<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wx</span>
<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wh</span>
<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

<span class="n">expected_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
 <span class="p">[[</span> <span class="mf">0.01764008</span><span class="p">,</span>  <span class="mf">0.01823233</span><span class="p">,</span>  <span class="mf">0.01882671</span><span class="p">,</span>  <span class="mf">0.0194232</span> <span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.11287491</span><span class="p">,</span>  <span class="mf">0.12146228</span><span class="p">,</span>  <span class="mf">0.13018446</span><span class="p">,</span>  <span class="mf">0.13902939</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.31358768</span><span class="p">,</span>  <span class="mf">0.33338627</span><span class="p">,</span>  <span class="mf">0.35304453</span><span class="p">,</span>  <span class="mf">0.37250975</span><span class="p">]],</span>
 <span class="p">[[</span> <span class="mf">0.45767879</span><span class="p">,</span>  <span class="mf">0.4761092</span><span class="p">,</span>   <span class="mf">0.4936887</span><span class="p">,</span>   <span class="mf">0.51041945</span><span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.6704845</span><span class="p">,</span>   <span class="mf">0.69350089</span><span class="p">,</span>  <span class="mf">0.71486014</span><span class="p">,</span>  <span class="mf">0.7346449</span> <span class="p">],</span>
  <span class="p">[</span> <span class="mf">0.81733511</span><span class="p">,</span>  <span class="mf">0.83677871</span><span class="p">,</span>  <span class="mf">0.85403753</span><span class="p">,</span>  <span class="mf">0.86935314</span><span class="p">]]])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;h error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">expected_h</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>h error:  8.610537442272635e-08
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="LSTM:-backward">LSTM: backward<a class="anchor-link" href="#LSTM:-backward">&#182;</a></h2><p>Testing <code>lstm.backward</code> for an entire timeseries of data.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">231</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span>

<span class="n">lstm</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">init_scale</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;test_lstm&#39;</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>
<span class="n">Wh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span>

<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wx</span>
<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Wh</span>
<span class="n">lstm</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

<span class="n">dout</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">dx</span><span class="p">,</span> <span class="n">dh0</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dout</span><span class="p">)</span>
<span class="n">dWx</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wx_name</span><span class="p">]</span> 
<span class="n">dWh</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">wh_name</span><span class="p">]</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">grads</span><span class="p">[</span><span class="n">lstm</span><span class="o">.</span><span class="n">b_name</span><span class="p">]</span>

<span class="n">dx_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">dh0_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">h0</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">h0</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">dWx_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">Wx</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">Wx</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">dWh_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">Wh</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">Wh</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>
<span class="n">db_num</span> <span class="o">=</span> <span class="n">eval_numerical_gradient_array</span><span class="p">(</span><span class="k">lambda</span> <span class="n">b</span><span class="p">:</span> <span class="n">lstm</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h0</span><span class="p">),</span> <span class="n">b</span><span class="p">,</span> <span class="n">dout</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dx_num</span><span class="p">,</span> <span class="n">dx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dh0 error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dh0_num</span><span class="p">,</span> <span class="n">dh0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dWx error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dWx_num</span><span class="p">,</span> <span class="n">dWx</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;dWh error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">dWh_num</span><span class="p">,</span> <span class="n">dWh</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;db error: &#39;</span><span class="p">,</span> <span class="n">rel_error</span><span class="p">(</span><span class="n">db_num</span><span class="p">,</span> <span class="n">db</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>dx error:  1.1836090780211367e-09
dh0 error:  4.534953544517244e-10
dWx error:  1.6965522923029384e-09
dWh error:  1.310330323958345e-07
db error:  3.715229506682041e-10
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="LSTM-model">LSTM model<a class="anchor-link" href="#LSTM-model">&#182;</a></h2><p>Testing lstm implementation using <code>TestNN</code> with <code>cell_type='lstm'</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">N</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span>
<span class="n">V</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">13</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TestRNN</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">cell_type</span><span class="o">=</span><span class="s1">&#39;lstm&#39;</span><span class="p">)</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">temporal_softmax_CE_loss</span><span class="p">()</span>

<span class="c1"># Set all model parameters to fixed values</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">model</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.4</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">size</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">assign_params</span><span class="p">()</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">D</span> <span class="o">*</span> <span class="n">T</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
<span class="n">h0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">H</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span> <span class="o">%</span> <span class="n">V</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>

<span class="c1"># You&#39;ll need this</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">))</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="n">dLoss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="n">expected_loss</span> <span class="o">=</span> <span class="mf">49.2140256354</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loss: &#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;expected loss: &#39;</span><span class="p">,</span> <span class="n">expected_loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;difference: &#39;</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="n">loss</span> <span class="o">-</span> <span class="n">expected_loss</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>loss:  49.21402563544293
expected loss:  49.2140256354
difference:  4.293099209462525e-11
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Generating-Text">Generating Text<a class="anchor-link" href="#Generating-Text">&#182;</a></h1><p>Train RNN on Alice's Adventures in Wonderland (Text Source: <a href="https://www.gutenberg.org/ebooks/11">link</a>, Project Gutenberg)</p>
<p>(To simplify training, only the first chapter is used here)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">input_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/alice.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">input_text</span> <span class="o">=</span> <span class="n">input_file</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="n">input_text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Construct the training dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="kn">import</span> <span class="nn">re</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; |</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">input_text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>  <span class="c1"># all words are converted into lower case</span>
<span class="n">outputSize</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">word_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
<span class="n">dataSize</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_list</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">outputSize</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">outputSize</span><span class="p">):</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">word_list</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
<span class="n">gt_labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input text size: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">outputSize</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input word number: </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">dataSize</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Input text size: 2170
Input word number: 778
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-and-train-an-instance-of-the-LanguageModelRNN-class-defined-in-rnn.py">Create and train an instance of the <code>LanguageModelRNN</code> class defined in <code>rnn.py</code><a class="anchor-link" href="#Create-and-train-an-instance-of-the-LanguageModelRNN-class-defined-in-rnn.py">&#182;</a></h3><p>RNN Architecture:</p>
<ul>
<li>a word_embedding layer</li>
<li>recurrent unit</li>
<li>temporal fully connected layer</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[36]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="c1"># you can change the following parameters.</span>
<span class="n">D</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># input dimension</span>
<span class="n">H</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># hidden space dimension</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># timesteps</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># batch size</span>
<span class="n">max_epoch</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># max epoch size</span>

<span class="n">loss_func</span> <span class="o">=</span> <span class="n">temporal_softmax_CE_loss</span><span class="p">()</span>
<span class="c1"># you can change the cell_type between &#39;rnn&#39; and &#39;lstm&#39;.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LanguageModelRNN</span><span class="p">(</span><span class="n">dataSize</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">cell_type</span><span class="o">=</span><span class="s1">&#39;lstm&#39;</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mf">5e-4</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;data_train&#39;</span><span class="p">:</span> <span class="n">input_data</span><span class="p">,</span> <span class="s1">&#39;labels_train&#39;</span><span class="p">:</span> <span class="n">gt_labels</span><span class="p">}</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">train_net</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epoch</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(Iteration 1 / 54200) loss: 665.7069847501157
(Iteration 501 / 54200) loss: 575.1992073450804
(Iteration 1001 / 54200) loss: 604.9944860569382
best performance 3.5961272475795294%
...
(Epoch 45 / 50) Training Accuracy: 0.9907791609036423
(Iteration 49001 / 54200) loss: 15.2759378574619
(Iteration 49501 / 54200) loss: 17.16236474943849
(Epoch 46 / 50) Training Accuracy: 0.9903181189488244
(Iteration 50001 / 54200) loss: 17.259392181153558
(Iteration 50501 / 54200) loss: 23.048019511928572
best performance 99.12402028584602%
(Epoch 47 / 50) Training Accuracy: 0.9912402028584602
(Iteration 51001 / 54200) loss: 9.120802359632746
(Iteration 51501 / 54200) loss: 13.80238781450254
(Iteration 52001 / 54200) loss: 19.713389523552195
best performance 99.1701244813278%
(Epoch 48 / 50) Training Accuracy: 0.991701244813278
(Iteration 52501 / 54200) loss: 13.116221374379055
(Iteration 53001 / 54200) loss: 7.700536077057679
best performance 99.21622867680959%
(Epoch 49 / 50) Training Accuracy: 0.9921622867680959
(Iteration 53501 / 54200) loss: 11.376942193152779
(Iteration 54001 / 54200) loss: 14.99557281489629
best performance 99.26233287229138%
(Epoch 50 / 50) Training Accuracy: 0.9926233287229138
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Check the loss and accuracy curve. Modify hyperparameters as needed to improve accuracy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[37]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="n">opt_params</span><span class="p">,</span> <span class="n">loss_hist</span><span class="p">,</span> <span class="n">train_acc_hist</span> <span class="o">=</span> <span class="n">results</span>

<span class="c1"># Plot the learning curves</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="n">loss_hist_</span> <span class="o">=</span> <span class="n">loss_hist</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">100</span><span class="p">]</span>  <span class="c1"># sparse the curve a bit</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_hist_</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Iteration&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_acc_hist</span><span class="p">,</span> <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Generate-text-using-the-trained-model">Generate text using the trained model<a class="anchor-link" href="#Generate-text-using-the-trained-model">&#182;</a></h3><p>Example of expected output:</p>
<blockquote><p>she was dozing off, and book-shelves; here and she tried to curtsey as she spoke--fancy curtseying as youre falling through the little door into a dreamy sort of way, do cats eat bats? do cats eat bats? and sometimes,</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[43]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">reload_ext</span> autoreload

<span class="c1"># you can change the generated text length below.</span>
<span class="n">text_length</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># you also can start from specific word. </span>
<span class="c1"># since the words are all converted into lower case</span>
<span class="n">idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">word_list</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;She&#39;</span><span class="o">.</span><span class="n">lower</span><span class="p">())[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># sample from the trained model</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">text_length</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># convert indices into words</span>
<span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>she was now the right size for going through the little door into that lovely garden. first, however, she waited for a few minutes to see if she was going to shrink any further: she felt a little nervous about this; for it might end, you know, said alice to herself, in my going out altogether, like a candle. i wonder what i should be like then? and she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing.  after a
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Observations-and-Reflections">Observations and Reflections<a class="anchor-link" href="#Observations-and-Reflections">&#182;</a></h2><p>Vanilla RNN's perform worse than LSTM for the same hyperparameters. Text generated from RNN models can be more repetitive. This repetition becomes more noticible the greater the difference between the batch size used during training and the generated text length. Moreover, the text often does not make any sense symantically. Increasing the timesteps of the RNN technically improved the objective accuracy (&gt;99%); however, the resulting text generated made no sense (ex. T=100 Rnn: "she croquet cried. lost: among got lying nice, bats? coming sitting curtsey that; burn plainly see, because thump! ...").</p>
<p>On the other hand, I was actually pretty impressed with the text generated with the LSTM model. Although the training accuracy was only slightly higher than that of the RNN model, the text generated made significantly more sense for all settings. Changing the timestep and text length settings didn't really affect the quailty of the text results. However, modifying the batch size resulted in improved accuracy scores form ~50% to &gt;98%. This improved training accuracy was also observed to correspond to significantly better text generation.</p>
<p>The limitations of the Vanilla RNN could be attributed to the lack of both a cell state and a forget gate. The lack of a cell state means the RNN doesn't have long-term persistant memory, meaning consistency between sentences/phrases is not maintained. Also, the lack of a forget gate and the recurrance nature of the model means that longer training (larger T) may actually hurt performance and is suscepitble to outliers as the weights of uncommon patterns are propagated throughout the network, obscuring earlier learned patterns.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sample observations:
LSTM
T = 50  # timesteps
N = 2 # batch size
(Iteration 54001 / 54200) loss: 19.704904365099825
best performance 98.2941447671738%
(Epoch 50 / 50) Training Accuracy: 0.9829414476717381</p>
<p>(Iteration 54001 / 54200) loss: 14.99557281489629
best performance 99.26233287229138%
(Epoch 50 / 50) Training Accuracy: 0.9926233287229138
she was now the right size for going through the little door into that lovely garden. first, however, she waited for a few minutes to see if she was going to shrink any further: she felt a little nervous about this; for it might end, you know, said alice to herself, in my going out altogether, like a candle. i wonder what i should be like then? and she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing.  after a</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sample Observations:
RNN 
batch size=2, 40 wrods
Training Accuracy: 0.9511295527893038
she was now the right size for going through the little door about fifteen inches high: she tried the little door about fifteen inches high: she tried the little door about fifteen inches high: she tried the little door about</p>
<p>batch size 10, 100 words
10800 iterations 
best performance 72.52189949285385%
(Epoch 50 / 50) Training Accuracy: 0.7252189949285385
she had never before seen one to be two people! why, theres hardly enough of the well, and seemed began talking again. dinahll miss me very much to-night, i shall have to ask them what the flame of a book, thought poor alice, it would be shutting and was not a very good opportunity for showing off her knowledge, as she had never before seen one to be two people! why, theres hardly enough of the well, and seemed began talking again. dinahll miss me very much to-night, i shall have to ask them what the flame of a book,</p>

</div>
</div>
</div>
    </div>
  </div>
</body>

{% include 'layout/components/footer.html' %}
{% include 'layout/components/footer-scripts.html' %}


</html>
